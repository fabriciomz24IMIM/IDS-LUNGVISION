{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c77b334-e995-48cc-87f8-aab30d51cfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# PART 2: ASTHMA ONSET PREDICTION\n",
    "# ================================================================\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.metrics import (roc_auc_score, classification_report, confusion_matrix, \n",
    "                             accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             precision_recall_curve, roc_curve, auc)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD DATA & CREATE ONSET LABELS\n",
    "# ============================================================================\n",
    "\n",
    "train_original = pd.read_csv(\"train_cleaned.csv\")\n",
    "test_original = pd.read_csv(\"test_cleaned.csv\")\n",
    "\n",
    "with open(\"weight_info.pkl\", \"rb\") as f:\n",
    "    weight_info = pickle.load(f)\n",
    "\n",
    "# Filter for asthmatic patients only\n",
    "train_asthma = train_original[train_original['Asthmatic'] == 1].copy()\n",
    "test_asthma = test_original[test_original['Asthmatic'] == 1].copy()\n",
    "\n",
    "# Create onset labels: 0=Childhood (<18), 1=Adult (≥18)\n",
    "def create_onset_label(row):\n",
    "    age_at_diagnosis = row.get('Age when first had asthma', np.nan)\n",
    "    if pd.isna(age_at_diagnosis):\n",
    "        return np.nan\n",
    "    return 0 if age_at_diagnosis < 18 else 1\n",
    "\n",
    "train_asthma['Onset_Type'] = train_asthma.apply(create_onset_label, axis=1)\n",
    "test_asthma['Onset_Type'] = test_asthma.apply(create_onset_label, axis=1)\n",
    "\n",
    "# Remove cases with missing onset info\n",
    "train_asthma = train_asthma[train_asthma['Onset_Type'].notna()].copy()\n",
    "test_asthma = test_asthma[test_asthma['Onset_Type'].notna()].copy()\n",
    "\n",
    "train_childhood = (train_asthma['Onset_Type'] == 0).sum()\n",
    "train_adult = (train_asthma['Onset_Type'] == 1).sum()\n",
    "test_childhood = (test_asthma['Onset_Type'] == 0).sum()\n",
    "test_adult = (test_asthma['Onset_Type'] == 1).sum()\n",
    "\n",
    "print(f\"Train: Childhood={train_childhood}, Adult={train_adult}\")\n",
    "print(f\"Test: Childhood={test_childhood}, Adult={test_adult}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f041e6-197a-4820-91a9-799a74c2e87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FEATURE SELECTION\n",
    "# ============================================================================\n",
    "\n",
    "exclude_cols = [\n",
    "    'SEQN',\n",
    "    'Age',  # CRITICAL: Age is confounded with time since diagnosis\n",
    "    'Full sample 2 year interview weight',\n",
    "    'Full sample 2 year MEC exam weight',\n",
    "    'Asthmatic',\n",
    "    'Age when first had asthma',\n",
    "    'Still have asthma',\n",
    "    'Asthma attack in past year',\n",
    "    'Emergency care visit for asthma/past yr',\n",
    "    'Onset_Type'\n",
    "]\n",
    "\n",
    "features = [col for col in train_asthma.columns if col not in exclude_cols]\n",
    "\n",
    "# ============================================================================\n",
    "# PREPARE DATA\n",
    "# ============================================================================\n",
    "\n",
    "X_train = train_asthma[features].copy()\n",
    "y_train = train_asthma['Onset_Type'].copy()\n",
    "X_test = test_asthma[features].copy()\n",
    "y_test = test_asthma['Onset_Type'].copy()\n",
    "\n",
    "train_weights = train_asthma[weight_info['interview_weight']].values\n",
    "test_weights = test_asthma[weight_info['interview_weight']].values\n",
    "\n",
    "# Handle missing values\n",
    "missing_count = X_train.isnull().sum().sum() + X_test.isnull().sum().sum()\n",
    "if missing_count > 0:\n",
    "    for col in X_train.columns:\n",
    "        if X_train[col].isnull().any():\n",
    "            median_val = X_train[col].median()\n",
    "            X_train[col] = X_train[col].fillna(median_val)\n",
    "            X_test[col] = X_test[col].fillna(median_val)\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_cols = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "if categorical_cols:\n",
    "    X_combined = pd.concat([X_train, X_test], axis=0, keys=['train', 'test'])\n",
    "    X_combined = pd.get_dummies(X_combined, columns=categorical_cols, drop_first=True)\n",
    "    X_train = X_combined.loc['train'].copy()\n",
    "    X_test = X_combined.loc['test'].copy()\n",
    "\n",
    "X_train = X_train.astype(float)\n",
    "X_test = X_test.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd94ead-95b9-4d7a-8154-66d38e805528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CROSS-VALIDATION SETUP\n",
    "# ============================================================================\n",
    "\n",
    "n_folds = 5\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "cv_results = {\n",
    "    'LR': {'auc': [], 'accuracy': [], 'f1': []},\n",
    "    'XGB': {'auc': [], 'accuracy': [], 'f1': []},\n",
    "    'RF': {'auc': [], 'accuracy': [], 'f1': []},\n",
    "    'ET': {'auc': [], 'accuracy': [], 'f1': []}\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# CROSS-VALIDATION LOOP\n",
    "# ============================================================================\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train), 1):\n",
    "    print(f\"\\nFold {fold}/{n_folds}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "    w_tr, w_val = train_weights[train_idx], train_weights[val_idx]\n",
    "    \n",
    "    # Balance classes\n",
    "    class_weights = compute_sample_weight('balanced', y_tr)\n",
    "    w_tr_balanced = w_tr * class_weights\n",
    "    w_tr_balanced = w_tr_balanced * (w_tr.sum() / w_tr_balanced.sum())\n",
    "    \n",
    "    # Standardize\n",
    "    scaler = StandardScaler()\n",
    "    X_tr_scaled = scaler.fit_transform(X_tr)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    \n",
    "    # Train and evaluate each model\n",
    "    \n",
    "    # Logistic Regression\n",
    "    lr = LogisticRegression(C=1.0, solver='lbfgs', max_iter=1000, random_state=42)\n",
    "    lr.fit(X_tr_scaled, y_tr, sample_weight=w_tr_balanced)\n",
    "    lr_proba = lr.predict_proba(X_val_scaled)[:, 1]\n",
    "    lr_pred = (lr_proba >= 0.5).astype(int)\n",
    "    \n",
    "    cv_results['LR']['auc'].append(roc_auc_score(y_val, lr_proba, sample_weight=w_val))\n",
    "    cv_results['LR']['accuracy'].append(accuracy_score(y_val, lr_pred, sample_weight=w_val))\n",
    "    cv_results['LR']['f1'].append(f1_score(y_val, lr_pred, sample_weight=w_val, zero_division=0))\n",
    "    \n",
    "    # XGBoost\n",
    "    fold_childhood = (y_tr == 0).sum()\n",
    "    fold_adult = (y_tr == 1).sum()\n",
    "    scale_pos_weight = fold_adult / fold_childhood if fold_childhood > 0 else 1.0\n",
    "    \n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        n_estimators=150, max_depth=4, learning_rate=0.05,\n",
    "        subsample=0.8, colsample_bytree=0.8,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        random_state=42, eval_metric='auc', use_label_encoder=False\n",
    "    )\n",
    "    xgb_model.fit(X_tr, y_tr, sample_weight=w_tr_balanced, verbose=False)\n",
    "    xgb_proba = xgb_model.predict_proba(X_val)[:, 1]\n",
    "    xgb_pred = (xgb_proba >= 0.5).astype(int)\n",
    "    \n",
    "    cv_results['XGB']['auc'].append(roc_auc_score(y_val, xgb_proba, sample_weight=w_val))\n",
    "    cv_results['XGB']['accuracy'].append(accuracy_score(y_val, xgb_pred, sample_weight=w_val))\n",
    "    cv_results['XGB']['f1'].append(f1_score(y_val, xgb_pred, sample_weight=w_val, zero_division=0))\n",
    "    \n",
    "    # Random Forest\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=200, max_depth=8, min_samples_split=20,\n",
    "        min_samples_leaf=10, random_state=42, n_jobs=-1\n",
    "    )\n",
    "    rf.fit(X_tr, y_tr, sample_weight=w_tr_balanced)\n",
    "    rf_proba = rf.predict_proba(X_val)[:, 1]\n",
    "    rf_pred = (rf_proba >= 0.5).astype(int)\n",
    "    \n",
    "    cv_results['RF']['auc'].append(roc_auc_score(y_val, rf_proba, sample_weight=w_val))\n",
    "    cv_results['RF']['accuracy'].append(accuracy_score(y_val, rf_pred, sample_weight=w_val))\n",
    "    cv_results['RF']['f1'].append(f1_score(y_val, rf_pred, sample_weight=w_val, zero_division=0))\n",
    "    \n",
    "    # Extra Trees\n",
    "    et = ExtraTreesClassifier(\n",
    "        n_estimators=200, max_depth=12, min_samples_split=15,\n",
    "        min_samples_leaf=8, random_state=42, n_jobs=-1\n",
    "    )\n",
    "    et.fit(X_tr, y_tr, sample_weight=w_tr_balanced)\n",
    "    et_proba = et.predict_proba(X_val)[:, 1]\n",
    "    et_pred = (et_proba >= 0.5).astype(int)\n",
    "    \n",
    "    cv_results['ET']['auc'].append(roc_auc_score(y_val, et_proba, sample_weight=w_val))\n",
    "    cv_results['ET']['accuracy'].append(accuracy_score(y_val, et_pred, sample_weight=w_val))\n",
    "    cv_results['ET']['f1'].append(f1_score(y_val, et_pred, sample_weight=w_val, zero_division=0))\n",
    "\n",
    "# ============================================================================\n",
    "# SUMMARIZE CV RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "cv_summary = []\n",
    "for model_name, metrics in cv_results.items():\n",
    "    cv_summary.append({\n",
    "        'Model': model_name,\n",
    "        'CV_AUC_Mean': np.mean(metrics['auc']),\n",
    "        'CV_AUC_Std': np.std(metrics['auc']),\n",
    "        'CV_Accuracy_Mean': np.mean(metrics['accuracy']),\n",
    "        'CV_Accuracy_Std': np.std(metrics['accuracy']),\n",
    "        'CV_F1_Mean': np.mean(metrics['f1']),\n",
    "        'CV_F1_Std': np.std(metrics['f1'])\n",
    "    })\n",
    "\n",
    "cv_summary_df = pd.DataFrame(cv_summary)\n",
    "cv_summary_df.to_csv('onset_cv_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f5e71b-be7b-423a-9d56-684bff4b00ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TRAIN FINAL MODELS ON FULL TRAINING SET\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\\nTraining final models on full training set...\")\n",
    "\n",
    "class_weights = compute_sample_weight('balanced', y_train)\n",
    "train_weights_balanced = train_weights * class_weights\n",
    "train_weights_balanced = train_weights_balanced * (train_weights.sum() / train_weights_balanced.sum())\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "models = {}\n",
    "predictions = {}\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(C=1.0, solver='lbfgs', max_iter=1000, random_state=42)\n",
    "lr.fit(X_train_scaled, y_train, sample_weight=train_weights_balanced)\n",
    "predictions['LR'] = lr.predict_proba(X_test_scaled)[:, 1]\n",
    "models['LR'] = lr\n",
    "\n",
    "# XGBoost\n",
    "scale_pos_weight = train_adult / train_childhood if train_childhood > 0 else 1.0\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=150, max_depth=4, learning_rate=0.05,\n",
    "    subsample=0.8, colsample_bytree=0.8,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42, eval_metric='auc', use_label_encoder=False\n",
    ")\n",
    "xgb_model.fit(X_train, y_train, sample_weight=train_weights_balanced, verbose=False)\n",
    "predictions['XGB'] = xgb_model.predict_proba(X_test)[:, 1]\n",
    "models['XGB'] = xgb_model\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200, max_depth=8, min_samples_split=20,\n",
    "    min_samples_leaf=10, random_state=42, n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train, sample_weight=train_weights_balanced)\n",
    "predictions['RF'] = rf.predict_proba(X_test)[:, 1]\n",
    "models['RF'] = rf\n",
    "\n",
    "# Extra Trees\n",
    "et = ExtraTreesClassifier(\n",
    "    n_estimators=200, max_depth=12, min_samples_split=15,\n",
    "    min_samples_leaf=8, random_state=42, n_jobs=-1\n",
    ")\n",
    "et.fit(X_train, y_train, sample_weight=train_weights_balanced)\n",
    "predictions['ET'] = et.predict_proba(X_test)[:, 1]\n",
    "models['ET'] = et\n",
    "\n",
    "# ============================================================================\n",
    "# EVALUATE ON TEST SET\n",
    "# ============================================================================\n",
    "\n",
    "results = []\n",
    "for name, proba in predictions.items():\n",
    "    pred = (proba >= 0.5).astype(int)\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_test, proba, sample_weight=test_weights)\n",
    "    acc = accuracy_score(y_test, pred, sample_weight=test_weights)\n",
    "    precision = precision_score(y_test, pred, sample_weight=test_weights, zero_division=0)\n",
    "    recall = recall_score(y_test, pred, sample_weight=test_weights, zero_division=0)\n",
    "    f1 = f1_score(y_test, pred, sample_weight=test_weights, zero_division=0)\n",
    "    \n",
    "    precision_childhood = precision_score(y_test, pred, pos_label=0, sample_weight=test_weights, zero_division=0)\n",
    "    recall_childhood = recall_score(y_test, pred, pos_label=0, sample_weight=test_weights, zero_division=0)\n",
    "    f1_childhood = f1_score(y_test, pred, pos_label=0, sample_weight=test_weights, zero_division=0)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Test_AUC': roc_auc,\n",
    "        'Test_Accuracy': acc,\n",
    "        'Test_Precision_Adult': precision,\n",
    "        'Test_Recall_Adult': recall,\n",
    "        'Test_F1_Adult': f1,\n",
    "        'Test_Precision_Childhood': precision_childhood,\n",
    "        'Test_Recall_Childhood': recall_childhood,\n",
    "        'Test_F1_Childhood': f1_childhood\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Merge with CV results\n",
    "final_results = cv_summary_df.merge(results_df, on='Model')\n",
    "final_results.to_csv('onset_detailed_metrics_with_cv.csv', index=False)\n",
    "\n",
    "\n",
    "# Get best model\n",
    "best_idx = results_df['Test_AUC'].idxmax()\n",
    "best_model_name = results_df.loc[best_idx, 'Model']\n",
    "best_proba = predictions[best_model_name]\n",
    "best_pred = (best_proba >= 0.5).astype(int)\n",
    "\n",
    "# Save confusion matrix\n",
    "cm = confusion_matrix(y_test, best_pred, sample_weight=test_weights)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm,\n",
    "    index=['Actual_Childhood', 'Actual_Adult'],\n",
    "    columns=['Predicted_Childhood', 'Predicted_Adult']\n",
    ")\n",
    "cm_df.to_csv('onset_confusion_matrix.csv')\n",
    "\n",
    "# Save classification report\n",
    "report_dict = classification_report(\n",
    "    y_test, best_pred, \n",
    "    sample_weight=test_weights,\n",
    "    target_names=['Childhood_Onset', 'Adult_Onset'],\n",
    "    output_dict=True,\n",
    "    zero_division=0\n",
    ")\n",
    "report_df = pd.DataFrame(report_dict).transpose()\n",
    "report_df.to_csv('onset_classification_report.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf097aab-1678-4dcc-9916-945baf91846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FEATURE IMPORTANCE\n",
    "# ============================================================================\n",
    "\n",
    "if best_model_name == 'LR':\n",
    "    importance = pd.DataFrame({\n",
    "        'Feature': X_train.columns,\n",
    "        'Importance': np.abs(models['LR'].coef_[0]),\n",
    "        'Coefficient': models['LR'].coef_[0],\n",
    "        'Direction': ['Adult↑' if c > 0 else 'Child↑' for c in models['LR'].coef_[0]]\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "else:\n",
    "    importance = pd.DataFrame({\n",
    "        'Feature': X_train.columns,\n",
    "        'Importance': models[best_model_name].feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "\n",
    "importance.to_csv('onset_feature_importance.csv', index=False)\n",
    "\n",
    "# ============================================================================\n",
    "# SAVE MODELS\n",
    "# ============================================================================\n",
    "\n",
    "joblib.dump(models['LR'], 'onset_lr_model.pkl')\n",
    "joblib.dump(models['XGB'], 'onset_xgb_model.pkl')\n",
    "joblib.dump(models['RF'], 'onset_rf_model.pkl')\n",
    "joblib.dump(models['ET'], 'onset_et_model.pkl')\n",
    "joblib.dump(scaler, 'onset_scaler.pkl')\n",
    "\n",
    "predictions_df = pd.DataFrame({\n",
    "    'y_true': y_test,\n",
    "    'lr_proba': predictions['LR'],\n",
    "    'xgb_proba': predictions['XGB'],\n",
    "    'rf_proba': predictions['RF'],\n",
    "    'et_proba': predictions['ET'],\n",
    "    'best_prediction': best_pred,\n",
    "    'test_weight': test_weights\n",
    "})\n",
    "predictions_df.to_csv('onset_predictions.csv', index=False)\n",
    "\n",
    "# Save CV results per fold for visualization\n",
    "cv_folds_data = []\n",
    "for model_name, metrics in cv_results.items():\n",
    "    for fold_idx, (auc_val, acc_val, f1_val) in enumerate(zip(metrics['auc'], metrics['accuracy'], metrics['f1']), 1):\n",
    "        cv_folds_data.append({\n",
    "            'Model': model_name,\n",
    "            'Fold': fold_idx,\n",
    "            'AUC': auc_val,\n",
    "            'Accuracy': acc_val,\n",
    "            'F1': f1_val\n",
    "        })\n",
    "\n",
    "cv_folds_df = pd.DataFrame(cv_folds_data)\n",
    "cv_folds_df.to_csv('onset_cv_folds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf07bd5-1a92-48c0-b657-43808fec068c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SHAP ANALYSIS: CHILDHOOD vs ADULT ASTHMA ONSET\n",
    "# =============================================================\n",
    "#!pip install shap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import joblib\n",
    "import warnings\n",
    "import json\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD MODEL AND DATA\n",
    "# ============================================================================\n",
    "\n",
    "xgb_model = joblib.load('onset_xgb_model.pkl')\n",
    "X_test = pd.read_csv('X_test_onset.csv')\n",
    "y_test = pd.read_csv('y_test_onset.csv').values.ravel()\n",
    "predictions = pd.read_csv('onset_predictions.csv')\n",
    "\n",
    "# Class distribution\n",
    "childhood_count = (y_test == 0).sum()\n",
    "adult_count = (y_test == 1).sum()\n",
    "total_count = len(y_test)\n",
    "\n",
    "\n",
    "\n",
    "# Training set\n",
    "y_train = pd.read_csv('y_train_onset.csv').values.ravel()\n",
    "train_childhood = (y_train == 0).sum()\n",
    "train_adult = (y_train == 1).sum()\n",
    "\n",
    "# ============================================================================\n",
    "# COMPUTE SHAP VALUES\n",
    "# ============================================================================\n",
    "\n",
    "explainer = shap.TreeExplainer(xgb_model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "print(f\"SHAP values computed: {shap_values.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# CREATE SHAP DATAFRAME FOR ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "# Calculate mean absolute SHAP values for each feature\n",
    "mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "mean_shap = shap_values.mean(axis=0)\n",
    "\n",
    "shap_df = pd.DataFrame({\n",
    "    'Feature': X_test.columns,\n",
    "    'Mean_Abs_SHAP': mean_abs_shap,\n",
    "    'Mean_SHAP': mean_shap\n",
    "})\n",
    "\n",
    "# ============================================================================\n",
    "# FIGURE: SHAP SUMMARY PLOT \n",
    "# ============================================================================\n",
    "\n",
    "# Create SHAP summary plot (dot plot) with top 10 features\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "shap.summary_plot(\n",
    "    shap_values,\n",
    "    X_test,\n",
    "    max_display=10,\n",
    "    plot_type=\"dot\",\n",
    "    show=False,\n",
    "    color_bar_label=\"Feature value\"\n",
    ")\n",
    "\n",
    "# Get current colorbar and resize it\n",
    "cbar = plt.gcf().axes[-1]  # Get the colorbar axes\n",
    "cbar.set_aspect(20)  # Make it narrower (higher number = narrower)\n",
    "\n",
    "plt.title(\n",
    "    \"SHAP Summary Plot: Childhood vs Adult Onset Asthma (Top 10 Features)\",\n",
    "    fontsize=16,\n",
    "    fontweight='bold',\n",
    "    pad=20\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"shap_summary.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# SAVE INTERPRETATION DATA\n",
    "# ============================================================================\n",
    "\n",
    "# Sort by absolute importance for export\n",
    "interpretation_df = shap_df.sort_values('Mean_Abs_SHAP', ascending=False)\n",
    "interpretation_df.to_csv('shap_feature_interpretation.csv', index=False)\n",
    "\n",
    "# Identify strong predictors\n",
    "childhood_predictors = interpretation_df[interpretation_df['Mean_SHAP'] < -0.01].head(10)\n",
    "adult_predictors = interpretation_df[interpretation_df['Mean_SHAP'] > 0.01].head(10)\n",
    "\n",
    "# Save detailed interpretation\n",
    "with open('shap_interpretation.txt', 'w') as f:\n",
    "    f.write(\"SHAP FEATURE INTERPRETATION\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(f\"Dataset Distribution:\\n\")\n",
    "    f.write(f\"  Test - Childhood: {childhood_count} ({childhood_count/total_count*100:.1f}%)\\n\")\n",
    "    f.write(f\"  Test - Adult: {adult_count} ({adult_count/total_count*100:.1f}%)\\n\")\n",
    "    f.write(f\"  Ratio: {childhood_count/adult_count:.2f}:1 (Childhood:Adult)\\n\\n\")\n",
    "    \n",
    "    f.write(\"=\"*80 + \"\\n\")\n",
    "    f.write(\"Top 10 Features by Importance:\\n\\n\")\n",
    "    for i, row in interpretation_df.head(10).iterrows():\n",
    "        direction = \"→ ADULT\" if row['Mean_SHAP'] > 0.01 else \"→ CHILDHOOD\" if row['Mean_SHAP'] < -0.01 else \"→ NEUTRAL\"\n",
    "        f.write(f\"{row['Feature']:<50} {direction:<15} SHAP={row['Mean_SHAP']:+.4f}\\n\")\n",
    "    \n",
    "    f.write(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    f.write(\"CHILDHOOD ONSET Predictors (SHAP < -0.01):\\n\")\n",
    "    if len(childhood_predictors) > 0:\n",
    "        for i, row in childhood_predictors.iterrows():\n",
    "            f.write(f\"  • {row['Feature']}: {row['Mean_SHAP']:.4f}\\n\")\n",
    "    else:\n",
    "        f.write(\"  • No strong individual predictors found\\n\")\n",
    "    \n",
    "    f.write(\"\\nADULT ONSET Predictors (SHAP > 0.01):\\n\")\n",
    "    if len(adult_predictors) > 0:\n",
    "        for i, row in adult_predictors.iterrows():\n",
    "            f.write(f\"  • {row['Feature']}: {row['Mean_SHAP']:.4f}\\n\")\n",
    "    else:\n",
    "        f.write(\"  • No strong individual predictors found\\n\")\n",
    "\n",
    "print(\"\\nFile saved: shap_interpretation.txt\")\n",
    "\n",
    "# Save summary stats\n",
    "summary_stats = {\n",
    "    'test_samples': int(total_count),\n",
    "    'childhood_count': int(childhood_count),\n",
    "    'adult_count': int(adult_count),\n",
    "    'childhood_percent': float(childhood_count/total_count*100),\n",
    "    'adult_percent': float(adult_count/total_count*100),\n",
    "    'childhood_to_adult_ratio': float(childhood_count/adult_count),\n",
    "    'train_childhood': int(train_childhood),\n",
    "    'train_adult': int(train_adult),\n",
    "    'base_value': float(explainer.expected_value),\n",
    "    'mean_prediction': float(predictions['xgb_proba'].mean()),\n",
    "    'top_childhood_features': childhood_predictors['Feature'].tolist()[:5] if len(childhood_predictors) > 0 else [],\n",
    "    'top_childhood_shap': [float(x) for x in childhood_predictors['Mean_SHAP'].tolist()[:5]] if len(childhood_predictors) > 0 else [],\n",
    "    'top_adult_features': adult_predictors['Feature'].tolist()[:5] if len(adult_predictors) > 0 else [],\n",
    "    'top_adult_shap': [float(x) for x in adult_predictors['Mean_SHAP'].tolist()[:5]] if len(adult_predictors) > 0 else []\n",
    "}\n",
    "\n",
    "with open('shap_summary_stats.json', 'w') as f:\n",
    "    json.dump(summary_stats, f, indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
