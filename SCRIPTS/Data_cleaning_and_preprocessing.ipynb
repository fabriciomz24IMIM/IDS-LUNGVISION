{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Script for converting XPT into CSV files\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "EyBSrMdInjoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Folder containing the XPT files\n",
        "input_folder = \"C:\\\\Users\\\\Fabricio Montero\\\\OneDrive - Tartu Ülikool\\\\Autumn 2025\\\\Introduction to Data Science\\\\Project\\\\Raw datasets\\\\2011-2012\" #Update folder path here\n",
        "\n",
        "output_folder = \"C:\\\\Users\\\\Fabricio Montero\\\\OneDrive - Tartu Ülikool\\\\Autumn 2025\\\\Introduction to Data Science\\\\Project\\\\Converted to CSV\\\\2011-2012\" #Update folder path here\n",
        "\n",
        "# Create output folder if it doesn't exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Find all .xpt files (case-insensitive)\n",
        "xpt_files = glob.glob(os.path.join(input_folder, \"*.xpt\")) + \\\n",
        "            glob.glob(os.path.join(input_folder, \"*.XPT\"))\n",
        "\n",
        "for file_path in xpt_files:\n",
        "    file_name = os.path.basename(file_path)\n",
        "    csv_name = os.path.splitext(file_name)[0] + \".csv\"\n",
        "    csv_path = os.path.join(output_folder, csv_name)\n",
        "\n",
        "    print(f\"Converting {file_name} → {csv_name}\")\n",
        "\n",
        "    # Read and convert\n",
        "    df = pd.read_sas(file_path, format=\"xport\")\n",
        "    df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(\"✅ Conversion complete!\")"
      ],
      "metadata": {
        "id": "6pGDFAZFnVBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Script for removing irrelevant columns\n",
        "\n",
        "It checks each CSV file in a folder one by one\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "r3244Nd2oigO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Folders\n",
        "input_folder = \"C:\\\\Users\\\\Fabricio Montero\\\\OneDrive - Tartu Ülikool\\\\Autumn 2025\\\\Introduction to Data Science\\\\Project\\\\Converted to CSV\\\\2011-2012\" #Update folder path here (same as output from previous cell)\n",
        "output_folder = \"C:\\\\Users\\\\Fabricio Montero\\\\OneDrive - Tartu Ülikool\\\\Autumn 2025\\\\Introduction to Data Science\\\\Project\\\\Cleaned CSV files\\\\2011-2012\" #Update folder path here\n",
        "\n",
        "progress_file = \"processed_files_2011-2012.txt\"   # <-- tracks progress\n",
        "\n",
        "# Create output folder\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Load progress\n",
        "if os.path.exists(progress_file):\n",
        "\n",
        "    with open(progress_file, \"r\") as f:\n",
        "        processed = set(line.strip() for line in f.readlines())\n",
        "else:\n",
        "    processed = set()\n",
        "\n",
        "# Find all CSVs\n",
        "csv_files = glob.glob(os.path.join(input_folder, \"*.csv\"))\n",
        "\n",
        "for file_path in csv_files:\n",
        "    file_name = os.path.basename(file_path)\n",
        "\n",
        "    # Skip if already processed\n",
        "    if file_name in processed:\n",
        "        print(f\"Skipping (already cleaned): {file_name}\")\n",
        "        continue\n",
        "\n",
        "    print(f\"\\nProcessing file: {file_name}\")\n",
        "\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Show columns\n",
        "    print(\"\\nColumns in this file:\")\n",
        "    for col in df.columns:\n",
        "        print(\"  -\", col)\n",
        "\n",
        "    # Ask which columns to KEEP\n",
        "    keep = input(\"\\nEnter columns to KEEP (comma-separated): \")\n",
        "    cols_to_keep = [c.strip() for c in keep.split(\",\") if c.strip()]\n",
        "\n",
        "    # Keep only existing columns\n",
        "    df_cleaned = df[[c for c in cols_to_keep if c in df.columns]]\n",
        "\n",
        "    # Save output\n",
        "    output_path = os.path.join(output_folder, file_name)\n",
        "    df_cleaned.to_csv(output_path, index=False)\n",
        "\n",
        "    # Log progress\n",
        "    with open(progress_file, \"a\") as f:\n",
        "        f.write(file_name + \"\\n\")\n",
        "\n",
        "    print(f\"Saved cleaned file → {output_path}\")\n",
        "    print(f\"Progress saved!\")\n",
        "\n",
        "print(\"\\n✅ DONE — All files processed or skipped.\")"
      ],
      "metadata": {
        "id": "SIUvm4o6osvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Script for merging all the \"cleaned\" datasets into a single dataset\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "76xs7TKBo6jR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Folder with your CLEANED CSV files\n",
        "\n",
        "input_folder = \"C:\\\\Users\\\\Fabricio Montero\\\\OneDrive - Tartu Ülikool\\\\Autumn 2025\\\\Introduction to Data Science\\\\Project\\\\Cleaned CSV files\\\\2011-2012\" #Update folder path here (same as output from previous cell)\n",
        "\n",
        "# Load all CSV files\n",
        "csv_files = glob.glob(os.path.join(input_folder, \"*.csv\"))\n",
        "\n",
        "# Read all files into DataFrames\n",
        "dfs = [pd.read_csv(f) for f in csv_files]\n",
        "\n",
        "# Name of the ID column (change if needed)\n",
        "id_col = \"SEQN\"\n",
        "\n",
        "# Merge all DataFrames on ID using full outer join\n",
        "merged_df = reduce(lambda left, right: pd.merge(left, right, on=id_col, how=\"outer\"), dfs)\n",
        "\n",
        "# Save final merged dataset\n",
        "merged_df.to_csv(\"merged_dataset 2011-2012.csv\", index=False) #Change for 2013-2014 when required\n",
        "\n",
        "print(\"✅ All datasets merged into merged_dataset.csv\")"
      ],
      "metadata": {
        "id": "0KhDH8RCpCfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Script for renaming the columns of the merged dataset\n",
        "A diccionary (Word document) was created to keep record on the meaning of each column\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "U5gyAWyLpOrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"merged_dataset 2011-2012.csv\") #Change for 2013-2014 when required\n",
        "\n",
        "# Dictionary: old_name → new_name\n",
        "rename_map = {\n",
        "    \"ALQ142\": \"Alcohol consumption\",\n",
        "    \"URXUMS\": \"Urine albumin\",\n",
        "    \"URXCRS\": \"Urine creatinine\",\n",
        "    \"LBXSATSI\": \"Alanine Aminotransferase\",\n",
        "    \"LBDSALSI\": \"Albumin, refrigerated serum\",\n",
        "    \"LBXSAPSI\": \"Alkaline Phosphatase\",\n",
        "    \"LBXSASSI\": \"Aspartate Aminotransferase\",\n",
        "    \"LBXSC3SI\": \"Bicarbonate\",\n",
        "    \"LBDSBUSI\": \"Blood Urea Nitrogen\",\n",
        "    \"LBXSCK\": \"Creatine Phosphokinase\",\n",
        "    \"LBDSCRSI\": \"Creatinine, refrigerated serum\",\n",
        "    \"LBDSGBSI\": \"Globulin\",\n",
        "    \"LBDSGLSI\": \"Glucose, refrigerated serum\",\n",
        "    \"LBXSGTSI\": \"Gamma Glutamyl Transferase\",\n",
        "    \"LBDSIRSI\": \"Iron, refrigerated serum\",\n",
        "    \"LBXSLDSI\": \"Lactate Dehydrogenase\",\n",
        "    \"LBDSPHSI\": \"Phosphorus\",\n",
        "    \"LBXSKSI\": \"Potassium\",\n",
        "    \"LBXSNASI\": \"Sodium\",\n",
        "    \"LBDSTBSI\": \"Total Bilirubin\",\n",
        "    \"LBDSCASI\": \"Total Calcium\",\n",
        "    \"LBDSCHSI\": \"Cholesterol, refrigerated serum\",\n",
        "    \"LBDSTPSI\": \"Total Protein\",\n",
        "    \"LBDSTRSI\": \"Triglycerides, refrig serum\",\n",
        "    \"LBDSUASI\": \"Uric acid\",\n",
        "    \"BMXWT\": \"Weight\",\n",
        "    \"BMXBMI\": \"BMI\",\n",
        "    \"BMDBMIC\": \"BMI - Children/Youth\",\n",
        "    \"BMXHT\": \"Height\",\n",
        "    \"BPQ020\": \"High blood pressure\",\n",
        "    \"BPQ080\": \"High cholesterol level\",\n",
        "    \"LBXWBCSI\": \"White blood cell count\",\n",
        "    \"LBDLYMNO\": \"Lymphocytes\",\n",
        "    \"LBDMONO\": \"Monocytes\",\n",
        "    \"LBDEONO\": \"Eosinophils\",\n",
        "    \"LBDBANO\": \"Basophils\",\n",
        "    \"LBXRBCSI\": \"Red blood cell count\",\n",
        "    \"LBXHGB\": \"Hemoglobin\",\n",
        "    \"LBXHCT\": \"Hematocrit\",\n",
        "    \"LBXPLTSI\": \"Platelet count\",\n",
        "    \"RIAGENDR\": \"Gender\",\n",
        "    \"RIDAGEYR\": \"Age\",\n",
        "    \"RIDAGEMN\": \"Age (in months)\",\n",
        "    \"RIDRETH3\": \"Race/Ethnicity\",\n",
        "    \"ECQ020\": \"Mother smoked when pregnant\",\n",
        "    \"ECD070A\": \"Weight at birth\",\n",
        "    \"MCQ080E\": \"Child was overweight\",\n",
        "    \"LBDFERSI\": \"Ferritin\",\n",
        "    \"LBDRFOSI\": \"RBC folate\",\n",
        "    \"LBXGH\": \"Glycohemoglobin\",\n",
        "    \"LBDHDDSI\": \"Direct HDL-Cholesterol\",\n",
        "    \"HIQ011\": \"Covered by health insurance\",\n",
        "    \"HUQ010\": \"General health condition\",\n",
        "    \"MCQ010\": \"Asthmatic\",\n",
        "    \"MCQ025\": \"Age when first had asthma\",\n",
        "    \"MCQ035\": \"Still have asthma\",\n",
        "    \"MCQ040\": \"Asthma attack in past year\",\n",
        "    \"MCQ050\": \"Emergency care visit for asthma/past yr\",\n",
        "    \"MCQ080\": \"Doctor ever said you were overweight\",\n",
        "    \"MCQ160\": \"Congestive heart failure\",\n",
        "    \"MCQ160c\": \"Coronary heart disease\",\n",
        "    \"MCQ160d\": \"Angina/angina pectoris\",\n",
        "    \"MCQ160e\": \"Heart attacks\",\n",
        "    \"MCQ160m\": \"Thyroid problem\",\n",
        "    \"MCQ160p\": \"COPD, emphysema, ChB\",\n",
        "    \"MCQ220\": \"Cancer or malignancy\",\n",
        "    \"MCQ300b\": \"Close relative had asthma\",\n",
        "    \"MCQ160l\": \"Liver condition\",\n",
        "    \"MCQ510a\": \"Fatty liver\",\n",
        "    \"PAQ605\": \"Vigorous work activity\",\n",
        "    \"PAQ620\": \"Moderate work activity\",\n",
        "    \"PAQ635\": \"Walk or bicycle\",\n",
        "    \"PAQ650\": \"Vigorous recreational activities\",\n",
        "    \"PAQ665\": \"Moderate recreational activities\",\n",
        "    \"PAQ706\": \"Days physically active\",\n",
        "    \"SMQ020\": \"At least 100 cigarettes in life\",\n",
        "    \"SMD030\": \"Age started smoking\",\n",
        "    \"SMD650\": \"Avg cigarettes per day\",\n",
        "    \"SMQ621\": \"Cigarettes smoked in entire life (12-17)\",\n",
        "    \"SMD460\": \"Number of smoker relatives\",\n",
        "    \"SMD470\": \"Number of people who smoke inside the house\",\n",
        "    \"SMQ681\": \"Smoked tobacco last 5 days\",\n",
        "    \"SMQ690B\": \"Used pipes in last 5 days\",\n",
        "    \"SMQ690C\": \"Used cigars in last 5 days\",\n",
        "    \"SMQ690G\": \"Used Hookah, water pipes in last 5 days\",\n",
        "    \"SMQ690H\": \"Used E-cigarettes in last 5 days\",\n",
        "    \"SMQ851\": \"Used smokeless tobacco in last 5 days\",\n",
        "    \"SMQ800\": \"Used chewing tobacco in last 5 days\",\n",
        "    \"SMQ690E\": \"Used Snuff in last 5 days\",\n",
        "    \"SMQ690F\": \"Used Patch, gum, other in last 5 days\",\n",
        "    \"SMDANY\": \"Used any tobacco product in last 5 days\",\n",
        "    \"SSAGP\": \"Alpha-1-Acid Glycoprotein\",\n",
        "    \"LBDTCSI\": \"Total Cholesterol\",\n",
        "    \"LBDTRSI\": \"Triglyceride\",\n",
        "    \"LBDLDLSI\": \"LDL-Cholesterol, Friedewald\",\n",
        "    \"LBDLDMSI\": \"LDL-Cholesterol, Martin-Hopkins\",\n",
        "    \"LBDLDNSI\": \"LDL-Cholesterol, NIH equation 2\",\n",
        "    \"WTINT2YR\": \"Full sample 2 year interview weight\",\n",
        "    \"WTMEC2YR\": \"Full sample 2 year MEC exam weight\",\n",
        "    \"URXNAL\": \"Urinary Total NNAL\",\n",
        "    \"LBXTC\": \"Total Cholesterol\",\n",
        "    \"SMQ040\": \"Currently smokes\",\n",
        "    \"MCQ053\": \"Taking treatment for anemia\",\n",
        "    \"LBXEOA\": \"Ethylene Oxide\",\n",
        "    \"CDQ010\": \"Shortness of breath on stairs\",\n",
        "    \"ALQ130\": \"Avg # alcoholic drinks/day\",\n",
        "    \"SMQ680\": \"Used any tobacco product in last 5 days\",\n",
        "    \"SMD415\": \"Number of people who smoke inside the house\"\n",
        "}\n",
        "\n",
        "df = df.rename(columns=rename_map)\n",
        "\n",
        "df.to_csv(\"merged_dataset_2011-2012_renamed.csv\", index=False)\n",
        "\n",
        "print(\"✔ Columns renamed successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsfGA6AKpUkT",
        "outputId": "ad1115dc-0442-4914-833a-78450f752cd3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✔ Columns renamed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Script for cleaning the dataset\n",
        "It changes all the very small values into 0\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "z_g9yaqcpe07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(\"merged_dataset_2011-2012_renamed.csv\") #Change for 2013-2014 when needed\n",
        "\n",
        "\n",
        "# Any number whose absolute value is smaller than 1e-50 is set to 0\n",
        "df = df.mask(df.abs() < 1e-50, 0)\n",
        "\n",
        "df.to_csv(\"merged_dataset_2011-2012_renamed_and_cleaned.csv\", index=False)\n",
        "\n",
        "print(\"Done — all tiny floating-point artifacts replaced with 0\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zIx6dvxpvnO",
        "outputId": "156c3cad-2a18-476d-f1ec-03312613d8bc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done — all tiny floating-point artifacts replaced with 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Code to remove children that did not have blood tests performed on them\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vVl3i4RUqPNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"merged_dataset_2011-2012_renamed_and_cleaned.csv\") #Change for 2013-2014 when required\n",
        "\n",
        "# Column you renamed from MCQ010:\n",
        "age_col = \"Age\"   # change if different\n",
        "\n",
        "# Keep only asthma patients\n",
        "df_asthma = df[df[age_col] > 2].copy()\n",
        "\n",
        "df_asthma.to_csv(\"2011-2012_nhanes_data.csv\", index=False)\n",
        "\n",
        "print(\"Done — dataset now doesn't contain children without blood tests.\")\n",
        "print(\"Remaining rows:\", len(df_asthma))"
      ],
      "metadata": {
        "id": "NX-Lwrt4qP6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DATA PREPROCESSING\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "wRoUfiNEx2hE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFZlqDdOnDMU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"2011-2012_nhanes_data.csv\")\n",
        "t_df = pd.read_csv(\"2013-2014_nhanes_data.csv\")\n",
        "\n",
        "# Replace NHANES missing codes with NaN\n",
        "missing_codes = [7, 9, 77, 99, 777, 999, 7777, 9999, 77777, 99999]\n",
        "df = df.replace(missing_codes, np.nan)\n",
        "t_df = t_df.replace(missing_codes, np.nan)\n",
        "\n",
        "# Recode Gender: 1=Male→0, 2=Female→1\n",
        "if \"Gender\" in df.columns:\n",
        "    df[\"Gender\"] = df[\"Gender\"].map({1: 0, 2: 1})\n",
        "    t_df[\"Gender\"] = t_df[\"Gender\"].map({1: 0, 2: 1})\n",
        "\n",
        "# Recode binary features: 1=Yes→1, 2=No→0\n",
        "binary_cols = [\n",
        "    \"Asthmatic\", \"High blood pressure\", \"Mother smoked when pregnant\",\n",
        "    \"Still have asthma\", \"Asthma attack in past year\",\n",
        "    \"Emergency care visit for asthma/past yr\", \"Taking treatment for anemia\",\n",
        "    \"Vigorous work activity\", \"Vigorous recreational activities\",\n",
        "    \"Used any tobacco product in last 5 days\", \"At least 100 cigarettes in life\", \"Shortness of breath on stairs\", \"Child was overweight\"\n",
        "]\n",
        "for col in binary_cols:\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].map({1: 1, 2: 0})\n",
        "        t_df[col] = t_df[col].map({1: 1, 2: 0})\n",
        "\n",
        "# Currently smokes: 1,2→1 (yes), 3→0 (no)\n",
        "if \"Currently smokes\" in df.columns:\n",
        "    df[\"Currently smokes\"] = df[\"Currently smokes\"].map({1: 1, 2: 1, 3: 0})\n",
        "    t_df[\"Currently smokes\"] = t_df[\"Currently smokes\"].map({1: 1, 2: 1, 3: 0})\n",
        "\n",
        "# Merge datasets\n",
        "nhanes_merged = pd.concat([df, t_df], axis=0, ignore_index=True)\n",
        "\n",
        "# Check target variable\n",
        "print(f\"Asthma prevalence: {nhanes_merged['Asthmatic'].mean():.1%}\")\n",
        "\n",
        "# Save cleaned merged data\n",
        "nhanes_merged.to_csv(\"merged_nhanes_data_cleaned.csv\", index=False)"
      ]
    }
  ]
}