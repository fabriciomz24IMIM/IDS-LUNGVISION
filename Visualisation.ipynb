{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7b5555-ff38-42ab-a652-4097111a4546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================================\n",
    "# VISUALIZATIONS FOR ASTHMA RISK CLASSIFICATION MODEL\n",
    "# ===========================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style(\"white\")\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD DATA\n",
    "# ============================================================================\n",
    "\n",
    "# Load results\n",
    "comparison = pd.read_csv('model_comparison_final.csv')\n",
    "results_df = pd.read_csv('all_model_predictions.csv')\n",
    "y_test = results_df['y_true'].values\n",
    "test_weights = results_df['test_weight'].values\n",
    "\n",
    "# Load feature importance for best model\n",
    "try:\n",
    "    feature_imp = pd.read_csv('xgb_feature_importance.csv')\n",
    "    best_model_name = 'XGBoost'\n",
    "except:\n",
    "    # Fallback to any available\n",
    "    for model_prefix in ['xgb', 'rf', 'et', 'lr']:\n",
    "        try:\n",
    "            feature_imp = pd.read_csv(f'{model_prefix}_feature_importance.csv')\n",
    "            best_model_name = {'xgb': 'XGBoost', 'rf': 'Random Forest', \n",
    "                              'et': 'ExtraTrees', 'lr': 'Logistic Regression'}[model_prefix]\n",
    "            break\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "# ============================================================================\n",
    "# 1. MODEL COMPARISON BAR CHART\n",
    "# ============================================================================\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1']\n",
    "x = np.arange(len(comparison))\n",
    "width = 0.2\n",
    "\n",
    "colors = ['#f0555e', '#41b8d5', '#ebac45', '#92b382']\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    offset = width * (i - 1.5)\n",
    "    bars = ax.bar(x + offset, comparison[metric], width, \n",
    "                   label=metric, color=colors[i], alpha=0.8, edgecolor='none')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.3f}', ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "ax.set_xlabel('Model', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Score', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(comparison['Model'], rotation=0, ha='center', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='upper right', ncol=1, fontsize=12, frameon=True)\n",
    "ax.set_ylim([0, 1.0])\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_comparison_metrics.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18f033d-c8f8-4cfd-843e-f6cd26feb2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 2. ROC CURVES FOR ALL MODELS\n",
    "# ============================================================================\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5.5, 5))\n",
    "\n",
    "model_probas = {\n",
    "    'Logistic Regression': results_df['lr_proba'].values,\n",
    "    'XGBoost': results_df['xgb_proba'].values,\n",
    "    'Random Forest': results_df['rf_proba'].values,\n",
    "    'ExtraTrees': results_df['et_proba'].values,\n",
    "    'Ensemble': results_df['ensemble_proba'].values,\n",
    "    'KNN': results_df['knn_proba'].values\n",
    "}\n",
    "\n",
    "colors_roc = ['#e74c3c', '#3498db', '#2ecc71', '#f39c12', '#9b59b6', '#1abc9c']\n",
    "\n",
    "for (name, proba), color in zip(model_probas.items(), colors_roc):\n",
    "    fpr, tpr, _ = roc_curve(y_test, proba, sample_weight=test_weights)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    ax.plot(fpr, tpr, color=color, lw=2.5, \n",
    "            label=f'{name} (AUC = {roc_auc:.3f})')\n",
    "\n",
    "# Diagonal line\n",
    "ax.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Baseline (AUC = 0.500)')\n",
    "\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel('False Positive Rate', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('True Positive Rate', fontsize=14, fontweight='bold')\n",
    "ax.set_title('ROC Curves: Model Comparison', fontsize=14, fontweight='bold')\n",
    "#ax.legend(loc='lower right', ncol=1, fontsize=12, frameon=True)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('roc_curves_all_models.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69a2e4a-5e01-47c5-82d4-911fb243ad1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 3. RISK STRATIFICATION HORIZONTAL BAR CHART\n",
    "# ============================================================================\n",
    "\n",
    "risk_tiers = results_df['risk_tier'].values\n",
    "\n",
    "# Calculate statistics for each tier\n",
    "tier_stats = []\n",
    "for tier in ['Low', 'Moderate', 'High']:\n",
    "    mask = risk_tiers == tier\n",
    "    total_count = mask.sum()\n",
    "    asthma_count = y_test[mask].sum()\n",
    "    asthma_rate = y_test[mask].mean() * 100\n",
    "    tier_stats.append({\n",
    "        'Risk Tier': tier,\n",
    "        'Total Samples': total_count,\n",
    "        'Asthma Cases': int(asthma_count),\n",
    "        'Asthma Rate (%)': asthma_rate\n",
    "    })\n",
    "\n",
    "tier_df = pd.DataFrame(tier_stats)\n",
    "\n",
    "# Create single plot for asthma prevalence\n",
    "fig, ax = plt.subplots(figsize=(9, 3))\n",
    "\n",
    "y_pos = np.arange(len(tier_df))\n",
    "colors_risk = ['#2ecc71', '#f39c12', '#e74c3c']\n",
    "\n",
    "bars = ax.barh(y_pos, tier_df['Asthma Rate (%)'], color=colors_risk, alpha=0.8, edgecolor='none')\n",
    "ax.set_ylabel('Risk Tier', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Asthma Prevalence (%)', fontsize=14, fontweight='bold')\n",
    "ax.set_title('Asthma Prevalence by Risk Tier', fontsize=14, fontweight='bold')\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(tier_df['Risk Tier'], fontsize=14)\n",
    "ax.tick_params(axis='x', labelsize=14)\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlim([0, max(tier_df['Asthma Rate (%)']) * 1.2])\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Add value labels with sample count\n",
    "for bar, rate, samples in zip(bars, tier_df['Asthma Rate (%)'], tier_df['Total Samples']):\n",
    "    width = bar.get_width()\n",
    "    ax.text(width, bar.get_y() + bar.get_height()/2.,\n",
    "             f' {rate:.1f}% (n={samples})', ha='left', va='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('risk_stratification_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Calculate risk ratio\n",
    "low_rate = tier_df[tier_df['Risk Tier'] == 'Low']['Asthma Rate (%)'].values[0]\n",
    "high_rate = tier_df[tier_df['Risk Tier'] == 'High']['Asthma Rate (%)'].values[0]\n",
    "risk_ratio = high_rate / low_rate if low_rate > 0 else float('inf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11a3b3d-c156-43d7-88fe-c1fd6c9623bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 4. TREEMAP FOR TOP FEATURES WITH TEXT WRAPPING\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import textwrap\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD FEATURE IMPORTANCE DATA\n",
    "# ============================================================================\n",
    "\n",
    "# Load model comparison to find best model\n",
    "comparison = pd.read_csv('model_comparison_final.csv')\n",
    "best_model_row = comparison.loc[comparison['Composite'].idxmax()]\n",
    "best_model_name = best_model_row['Model']\n",
    "\n",
    "# Map model names to file prefixes\n",
    "model_to_prefix = {\n",
    "    'Logistic Regression': 'lr',\n",
    "    'XGBoost': 'xgb',\n",
    "    'Random Forest': 'rf',\n",
    "    'ExtraTrees': 'et'\n",
    "}\n",
    "\n",
    "# Load feature importance for best model\n",
    "best_prefix = model_to_prefix.get(best_model_name, 'xgb')\n",
    "feature_imp = pd.read_csv(f'{best_prefix}_feature_importance.csv')\n",
    "\n",
    "# ============================================================================\n",
    "# PREPARE DATA\n",
    "# ============================================================================\n",
    "\n",
    "# Get top N features\n",
    "top_n = 5\n",
    "if 'importance' in feature_imp.columns:\n",
    "    top_features = feature_imp.nlargest(top_n, 'importance')\n",
    "    importance_col = 'importance'\n",
    "elif 'abs_coefficient' in feature_imp.columns:\n",
    "    top_features = feature_imp.nlargest(top_n, 'abs_coefficient')\n",
    "    importance_col = 'abs_coefficient'\n",
    "else:\n",
    "    top_features = feature_imp.head(top_n)\n",
    "    importance_col = feature_imp.columns[1]\n",
    "\n",
    "# Normalize importances to sum to 360 degrees\n",
    "importances = top_features[importance_col].values\n",
    "angles = (importances / importances.sum()) * 360\n",
    "features = top_features['feature'].values\n",
    "\n",
    "# ============================================================================\n",
    "# CREATE TREEMAP\n",
    "# ============================================================================\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 10))\n",
    "\n",
    "# Color palette\n",
    "colors = ['#e74c3c', '#3498db', '#2ecc71', '#f39c12', '#9b59b6']\n",
    "\n",
    "# Sort by importance (descending)\n",
    "sorted_indices = np.argsort(importances)[::-1]\n",
    "features_sorted = features[sorted_indices]\n",
    "importances_sorted = importances[sorted_indices]\n",
    "\n",
    "# Normalize importances to get areas\n",
    "total_area = 1.0\n",
    "areas = importances_sorted / importances_sorted.sum() * total_area\n",
    "\n",
    "# Simple treemap layout algorithm (squarified layout)\n",
    "def squarify(sizes, x, y, width, height):\n",
    "    \"\"\"Create a simple squarified treemap layout\"\"\"\n",
    "    rectangles = []\n",
    "    \n",
    "    if len(sizes) == 0:\n",
    "        return rectangles\n",
    "    \n",
    "    if len(sizes) == 1:\n",
    "        rectangles.append((x, y, width, height))\n",
    "        return rectangles\n",
    "    \n",
    "    # Split vertically or horizontally based on aspect ratio\n",
    "    if width >= height:\n",
    "        # Split vertically\n",
    "        total = sum(sizes)\n",
    "        ratio = sizes[0] / total\n",
    "        width1 = width * ratio\n",
    "        rectangles.append((x, y, width1, height))\n",
    "        rectangles.extend(squarify(sizes[1:], x + width1, y, width - width1, height))\n",
    "    else:\n",
    "        # Split horizontally\n",
    "        total = sum(sizes)\n",
    "        ratio = sizes[0] / total\n",
    "        height1 = height * ratio\n",
    "        rectangles.append((x, y, width, height1))\n",
    "        rectangles.extend(squarify(sizes[1:], x, y + height1, width, height - height1))\n",
    "    \n",
    "    return rectangles\n",
    "\n",
    "# Get rectangle positions\n",
    "rectangles = squarify(areas.tolist(), 0, 0, 1, 1)\n",
    "\n",
    "# Draw rectangles\n",
    "for i, (rect, feature, importance, color) in enumerate(zip(rectangles, features_sorted, importances_sorted, colors)):\n",
    "    x, y, width, height = rect\n",
    "    \n",
    "    # Draw rectangle\n",
    "    rectangle = mpatches.Rectangle((x, y), width, height,\n",
    "                                   facecolor=color, \n",
    "                                   edgecolor='white',\n",
    "                                   linewidth=4,\n",
    "                                   alpha=0.85)\n",
    "    ax.add_patch(rectangle)\n",
    "    \n",
    "    # Calculate text wrapping based on rectangle width\n",
    "    text_x = x + width / 2\n",
    "    text_y = y + height / 2\n",
    "    \n",
    "    # Adjust font size based on rectangle size\n",
    "    font_size = min(14, int(min(width, height) * 80))\n",
    "    \n",
    "    # Calculate character width for wrapping (approximate)\n",
    "    # Each character is roughly 0.6 * font_size pixels, convert to data coordinates\n",
    "    chars_per_line = max(11, int(width * 100 / (font_size * 0.6)))\n",
    "    \n",
    "    # Wrap the feature name\n",
    "    wrapped_text = textwrap.fill(feature, width=chars_per_line)\n",
    "    \n",
    "    # Add feature name (wrapped)\n",
    "    ax.text(text_x, text_y + height * 0.08, wrapped_text,\n",
    "            ha='center', va='center',\n",
    "            fontsize=font_size, fontweight='bold',\n",
    "            color='white')\n",
    "    \n",
    "    # Add importance value\n",
    "    ax.text(text_x, text_y - height * 0.08, f'{importance:.4f}',\n",
    "            ha='center', va='center',\n",
    "            fontsize=font_size - 2,\n",
    "            color='white',\n",
    "            fontweight='bold')\n",
    "\n",
    "# Set limits and styling\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_aspect('equal')\n",
    "ax.axis('off')\n",
    "\n",
    "plt.title(f'Top {top_n} Feature Importance - {best_model_name}', \n",
    "          fontsize=18, fontweight='bold', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('treemap_top_features.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813dd55c-a3d3-4de9-9e08-3bab2a2bf651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ASTHMA ONSET PREDICTION VISUALIZATIONS\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for clean plots\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "plt.rcParams['savefig.facecolor'] = 'white'\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD DATA\n",
    "# ============================================================================\n",
    "\n",
    "# Load CV + Test results\n",
    "results_df = pd.read_csv('onset_detailed_metrics_with_cv.csv')\n",
    "predictions_df = pd.read_csv('onset_predictions.csv')\n",
    "cv_folds_df = pd.read_csv('onset_cv_folds.csv')\n",
    "\n",
    "y_test = predictions_df['y_true'].values\n",
    "test_weights = predictions_df['test_weight'].values\n",
    "\n",
    "# Model name mapping\n",
    "model_name_mapping = {\n",
    "    'LR': 'Logistic Regression',\n",
    "    'XGB': 'XGBoost',\n",
    "    'RF': 'Random Forest',\n",
    "    'ET': 'Extra Trees'\n",
    "}\n",
    "\n",
    "# Apply full names to results_df if needed\n",
    "if results_df['Model'].iloc[0] in model_name_mapping:\n",
    "    results_df['Model'] = results_df['Model'].map(model_name_mapping)\n",
    "\n",
    "# Create models dict with full names\n",
    "models = {\n",
    "    'Logistic Regression': predictions_df['lr_proba'].values,\n",
    "    'XGBoost': predictions_df['xgb_proba'].values,\n",
    "    'Random Forest': predictions_df['rf_proba'].values,\n",
    "    'Extra Trees': predictions_df['et_proba'].values\n",
    "}\n",
    "\n",
    "# Color palette - use full names\n",
    "colors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12']\n",
    "model_colors = dict(zip(['Logistic Regression', 'XGBoost', 'Random Forest', 'Extra Trees'], colors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd54c87f-39af-4ef3-b337-a3230c1a38cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PLOT 1: AUC-ROC CURVES\n",
    "# ============================================================================\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5.5, 5))\n",
    "\n",
    "for i, (name, proba) in enumerate(models.items()):\n",
    "    fpr, tpr, _ = roc_curve(y_test, proba, sample_weight=test_weights)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Get CV AUC for label\n",
    "    cv_auc = results_df.loc[results_df['Model']==name, 'CV_AUC_Mean'].values[0]\n",
    "    cv_std = results_df.loc[results_df['Model']==name, 'CV_AUC_Std'].values[0]\n",
    "    \n",
    "    ax.plot(fpr, tpr, linewidth=2.5, \n",
    "            label=f'{name} (Test={roc_auc:.3f}, CV={cv_auc:.3f}Â±{cv_std:.3f})',\n",
    "            color=model_colors[name])\n",
    "\n",
    "# Baseline\n",
    "ax.plot([0, 1], [0, 1], 'k--', linewidth=1.5, alpha=0.5, label='Random Baseline')\n",
    "\n",
    "ax.set_xlabel('False Positive Rate', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('True Positive Rate', fontsize=12, fontweight='bold')\n",
    "ax.set_title('ROC Curves - Asthma Onset Prediction', fontsize=14, fontweight='bold', pad=15)\n",
    "ax.legend(loc='lower right', fontsize=9, frameon=True, fancybox=True, shadow=True)\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_ylim([0, 1])\n",
    "\n",
    "# Remove top and right spines\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('onset_roc_curves.png', dpi=300, bbox_inches='tight', facecolor='none')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb60a34-3a8e-4b82-9874-fef3dc68629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PLOT 2: ALL METRICS IN SINGLE HORIZONTAL BAR CHART\n",
    "# ============================================================================\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 10))\n",
    "\n",
    "models_list = results_df['Model'].tolist()\n",
    "\n",
    "# Get test metrics only\n",
    "accuracy = results_df['Test_Accuracy'].values\n",
    "precision = results_df['Test_Precision_Adult'].values\n",
    "recall = results_df['Test_Recall_Adult'].values\n",
    "f1 = results_df['Test_F1_Adult'].values\n",
    "\n",
    "# Color scheme for metrics\n",
    "metric_colors = ['#f0555e', '#41b8d5', '#ebac45', '#92b382']\n",
    "\n",
    "# Create positions for grouped bars\n",
    "n_models = len(models_list)\n",
    "n_metrics = 4\n",
    "bar_height = 0.18\n",
    "y_positions = np.arange(n_models)\n",
    "\n",
    "# Plot each metric (no edge colors)\n",
    "bars1 = ax.barh(y_positions - 1.5*bar_height, accuracy, bar_height, \n",
    "                label='Accuracy', color=metric_colors[0], alpha=1)\n",
    "bars2 = ax.barh(y_positions - 0.5*bar_height, precision, bar_height, \n",
    "                label='Precision (Adult)', color=metric_colors[1], alpha=1)\n",
    "bars3 = ax.barh(y_positions + 0.5*bar_height, recall, bar_height, \n",
    "                label='Recall (Adult)', color=metric_colors[2], alpha=1)\n",
    "bars4 = ax.barh(y_positions + 1.5*bar_height, f1, bar_height, \n",
    "                label='F1 Score (Adult)', color=metric_colors[3], alpha=1)\n",
    "\n",
    "# Add value labels\n",
    "for i, (acc, prec, rec, f1_val) in enumerate(zip(accuracy, precision, recall, f1)):\n",
    "    ax.text(acc + 0.01, i - 1.5*bar_height, f'{acc:.3f}', \n",
    "            va='center', fontsize=9, fontweight='bold')\n",
    "    ax.text(prec + 0.01, i - 0.5*bar_height, f'{prec:.3f}', \n",
    "            va='center', fontsize=9, fontweight='bold')\n",
    "    ax.text(rec + 0.01, i + 0.5*bar_height, f'{rec:.3f}', \n",
    "            va='center', fontsize=9, fontweight='bold')\n",
    "    ax.text(f1_val + 0.01, i + 1.5*bar_height, f'{f1_val:.3f}', \n",
    "            va='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "ax.set_yticks(y_positions)\n",
    "ax.set_yticklabels(models_list, fontweight='bold', fontsize=14)\n",
    "ax.set_xlabel('Score', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Model', fontsize=14, fontweight='bold')\n",
    "ax.set_title('Model Performance Comparison - Test Set', fontsize=15, fontweight='bold', pad=15)\n",
    "ax.set_xlim([0, 1])\n",
    "#ax.legend(fontsize=12, frameon=True, fancybox=True, loc='upper right', ncol = 4)\n",
    "\n",
    "# Remove only top and right spines (keep x and y axis lines)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('onset_all_metrics.png', dpi=600, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755fbf8e-aaf7-4f33-ac60-4bcf819da9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PLOT 3: PROBABILITY DISTRIBUTION\n",
    "# ============================================================================\n",
    "\n",
    "# Get best model (based on Test AUC)\n",
    "best_model_name = results_df.loc[results_df['Test_AUC'].idxmax(), 'Model']\n",
    "best_proba = models[best_model_name]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 5))\n",
    "\n",
    "# Separate probabilities by true class\n",
    "childhood_proba = best_proba[y_test == 0]\n",
    "adult_proba = best_proba[y_test == 1]\n",
    "\n",
    "ax.hist(childhood_proba, bins=30, alpha=0.7, label='Childhood Onset (True)',\n",
    "        color='#3498db', edgecolor='black', linewidth=1.2, density=True)\n",
    "ax.hist(adult_proba, bins=30, alpha=0.7, label='Adult Onset (True)',\n",
    "        color='#e74c3c', edgecolor='black', linewidth=1.2, density=True)\n",
    "\n",
    "# Add threshold line\n",
    "ax.axvline(x=0.5, color='black', linestyle='--', linewidth=2, \n",
    "           label='Decision Threshold (0.5)', alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Predicted Probability (Adult Onset)', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Density', fontsize=14, fontweight='bold')\n",
    "ax.set_title(f'Probability Distribution - {best_model_name} Model', \n",
    "             fontsize=14, fontweight='bold', pad=15)\n",
    "ax.legend(fontsize=10, frameon=True, fancybox=True)\n",
    "\n",
    "# Remove top and right spines\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('onset_probability_distribution.png', dpi=600, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
